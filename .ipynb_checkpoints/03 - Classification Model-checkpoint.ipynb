{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the toolbox\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean and pre-labeled DataFrame\n",
    "\n",
    "df = pd.read_csv(\"./data/psth_data_IC_preclassified.csv\",index_col='id',keep_default_na=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf884dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "\n",
    "any(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic classification report\n",
    "\n",
    "display(df['pattern'].value_counts().drop(''))\n",
    "print(sum(df['pattern'] != ''), \"recordings met the criteria to be labeled in one category.\")\n",
    "print(round(sum(df['pattern'] == '')*100/len(df['pattern']),1), \"% of the recordings remain unlabeled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labeled from unlabeled data\n",
    "\n",
    "df_labeled = df[df['pattern'] != '']\n",
    "df_unlabeled = df[df['pattern'] == '']\n",
    "\n",
    "# X-y Split\n",
    "\n",
    "y = df_labeled['pattern']\n",
    "X = df_labeled.drop(columns='pattern')\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7ec0d",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_1=df_labeled['pattern'].value_counts() #value counts of the target directly from the dataset\n",
    "print(balance_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba0f67",
   "metadata": {},
   "source": [
    "### 1 - TOMEK Links undersampling\n",
    "\n",
    "First, we apply an undersampling technique to the X/y train dataframes from the X/y train/test split. This will serve to \"soften\" the clusters of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca928b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(sampling_strategy='not minority') # initialize Tomek Links\n",
    "\n",
    "#Apply undersampling to X_train and y_train\n",
    "X_train_tl_1, y_train_tl_1 = tl.fit_resample(X_train, y_train)  #X_train and y_train after TL 1\n",
    "display(y_train_tl_1.value_counts())\n",
    "balance_2=y_train_tl_1.value_counts() #value counts of the target after TL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb8f22",
   "metadata": {},
   "source": [
    "### 2 - SMOTE\n",
    "\n",
    "The imbalancing has improved, but it is not balanced enough yet. We next apply oversampling with SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_tl_1, y_train_tl_1)  #X_train and y_train after SMOTE\n",
    "display(y_train_sm.value_counts())\n",
    "balance_3=y_train_sm.value_counts() #value counts of the target after SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc5535",
   "metadata": {},
   "source": [
    "As expected, the oversampling has completely balanced the values in the y_train dataset. However, this is not real: many \"fake\" values have been added, and this could generate artificial predictions from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada175cd",
   "metadata": {},
   "source": [
    "### 3 - TOMEK Links polishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23624ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply undersampling again to X_train_sm and y_train_sm\n",
    "tl_ = TomekLinks(sampling_strategy='all') # change strategy because if they are all the same it won't do anything\n",
    "X_train_tl_2, y_train_tl_2 = tl_.fit_resample(X_train_sm, y_train_sm)  #X_train and y_train after TL 2\n",
    "display(y_train_tl_2.value_counts())\n",
    "balance_4=y_train_tl_2.value_counts() #value counts of the target after TL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e12db3",
   "metadata": {},
   "source": [
    "The balance of our data is seemingly good now. We proceed to train our model and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cdfb6f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb240506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logistic regression: initialize Logistic Regression and fit scaled TRAIN X and TRAIN y data (target)\n",
    "\n",
    "clf = SVC() #probability=True\n",
    "clf.fit(X_train_tl_2, y_train_tl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score and predictions\n",
    "\n",
    "print(\"Score =\",round(clf.score(X_test, y_test), 3))\n",
    "predictions = clf.predict(X_test)\n",
    "#pred_probs = clf.predict_proba(X_test) # To get the probability of each class\n",
    "display(pd.Series(predictions).value_counts())\n",
    "display(y_test.value_counts())\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix = confusion_matrix(y_test, predictions, labels=clf.classes_),\n",
    "    display_labels = clf.classes_\n",
    ").plot(cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities of each class\n",
    "\n",
    "#probs = pd.DataFrame(pred_probs, columns=clf.classes_, index=X_test.index)\n",
    "#unsure = probs[probs.max(axis=1)<0.99] # Get dubious cases\n",
    "#unsure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440542c",
   "metadata": {},
   "source": [
    "# MODEL APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = df_unlabeled.copy().drop(columns='pattern')\n",
    "df_predicted['pattern'] = clf.predict(df_predicted)\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "\n",
    "pattern = 'sustain' # Select the pattern you want to check\n",
    "\n",
    "# Stimulus: pure tone (75 ms). Interstimulus interval of 250 ms (4 Hz presentation rate)\n",
    "tone_x, tone_y = [0,75],[-0.05,-0.05] # info for Matplotlib\n",
    "\n",
    "for id in df_predicted[df_predicted['pattern'] == pattern].index:\n",
    "    df_predicted.drop(columns='pattern').loc[id].plot(kind='line')\n",
    "    plt.title(id)\n",
    "    plt.ylim([-0.1, 1])\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Spike density (norm)')\n",
    "    tone, = plt.plot(tone_x, tone_y, marker = 'o')\n",
    "    tone.set_label('Tone')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
